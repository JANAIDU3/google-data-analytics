# Course – 4: Process Data from Dirty to Clean

## Objectives

- **Define different types of data integrity** and identify risks to data integrity.
- **Apply basic SQL functions** to clean string variables in a database.
- **Develop basic SQL queries** for use on databases.
- **Describe the process of verifying data cleaning results.**

---

## Processing Data

### 1. **Data Integrity**
Data integrity refers to the **accuracy**, **completeness**, **consistency**, and **trustworthiness** of data throughout its lifecycle. Ensuring data integrity is essential for making accurate and reliable analyses.

#### Types of Data Integrity:
- **Physical Integrity**: Ensures that the data is not corrupted or lost during storage or transmission.
- **Logical Integrity**: Ensures that the data in the database accurately reflects the real-world values it represents.

### 2. **Data Replication**
Data replication involves **storing data in multiple locations** to ensure availability and fault tolerance. It's important for backup and disaster recovery strategies.

### 3. **Data Transfer**
Data transfer refers to the **copying of data** from a storage device to memory or transferring it between devices, such as from one computer to another.

### 4. **Data Manipulation**
Data manipulation is the process of **changing data** to make it more organized, easier to analyze, and more useful. This could involve:
- Cleaning data
- Formatting data
- Sorting data

---

## Threats to Data Integrity

Various factors can jeopardize data integrity, including:

- **Human Error**: Mistakes made during data entry or processing.
- **Viruses**: Malicious software that corrupts or manipulates data.
- **Malware**: Software designed to damage or exploit data.
- **System Failures**: Hardware or software malfunctions that affect data storage or transmission.
- **Hacking**: Unauthorized access to or manipulation of data by malicious actors.

---

## SQL for Data Cleaning

Using SQL functions is essential for cleaning string variables in databases. Some common tasks include:

- Removing leading/trailing spaces
- Converting data to consistent formats (e.g., upper/lower case)
- Replacing null or missing values with defaults

### Basic SQL Functions for Data Cleaning
- **TRIM()**: Removes leading and trailing spaces from string data.
- **UPPER()** or **LOWER()**: Converts text to uppercase or lowercase for consistency.
- **REPLACE()**: Replaces a substring within a string with another substring.
- **COALESCE()**: Replaces `NULL` values with a specified value.

---

## Verifying Data Cleaning Results

After cleaning the data, it's important to verify the results to ensure the accuracy and quality of the data. This can be done by:
- Running consistency checks
- Validating data against predefined rules or external sources
- Sampling data for manual inspection

---

## Insufficient Data

### Types of Insufficient Data:
- **Collecting Data from Only One Source**: Can limit the breadth and accuracy of insights.
- **Outdated Data**: Data that no longer reflects current conditions or trends.
- **Data That Keeps Updating**: Continuous changes in data can make it difficult to analyze or interpret.
- **Geographically Limited Data**: Data that is constrained to a specific location or region, which may not apply universally.

### Ways to Address Insufficient Data:
- **Identify Trends**: Look for patterns that could help inform conclusions in the absence of comprehensive data.
- **Look for New Datasets**: Seek out additional datasets from alternative sources to enrich your analysis.
- **Wait for More Data**: Sometimes, it's necessary to wait until more data is available to complete your analysis.
- **Talk with Stakeholders & Adjust Objectives**: Communicate with stakeholders to realign objectives based on available data or adjust expectations accordingly.

---

## Statistical Concepts

### 1. **Statistical Power**
Statistical power is the probability of getting **meaningful results** from a test. High statistical power indicates that the test is likely to detect an effect if there is one.

### 2. **Hypothesis Testing**
Hypothesis testing is a method used to determine whether the results of a **survey** or **experiment** are meaningful or due to random chance.

### 3. **Confidence Level**
The confidence level is the probability that the **sample size** accurately reflects the actual **population**. A higher confidence level means greater certainty in the results.

### 4. **Margin of Error**
The margin of error refers to the **maximum difference** between the sample results and the actual population. This value depends on:
- Population size
- Sample size
- Confidence level

---

## Data Types and Data Cleaning

### Clean Data
Clean data is data that is **complete**, **correct**, and **relevant**. It's essential for reliable analysis and decision-making.

### Types of Dirty Data
Dirty data can take several forms, such as:
1. **Duplicate Data**: Data that is repeated in the dataset.
2. **Outdated Data**: Information that is no longer valid or current.
3. **Incomplete Data**: Missing values or partial records.
4. **Incorrect/Inaccurate Data**: Data that is wrong or doesn't represent the intended value.
5. **Inconsistent Data**: Data that doesn't follow a standard format or contains conflicting values.

---

## Roles in Data Processing

### 1. **Data Engineers**
Data engineers transform data into a usable format for analysis and ensure that data infrastructure is reliable.

### 2. **Data Warehousing Specialists**
These professionals develop processes and procedures to **store** and **organize** data effectively in data warehouses, ensuring that data is accessible and properly managed.

---

## SQL for Data Cleaning

Using SQL functions is essential for cleaning string variables in databases. Some common tasks include:
- Removing leading/trailing spaces
- Converting data to consistent formats (e.g., upper/lower case)
- Replacing null or missing values with defaults

### Basic SQL Functions for Data Cleaning
- **TRIM()**: Removes leading and trailing spaces from string data.
- **UPPER()** or **LOWER()**: Converts text to uppercase or lowercase for consistency.
- **REPLACE()**: Replaces a substring within a string with another substring.
- **COALESCE()**: Replaces `NULL` values with a specified value.

---

## Verifying Data Cleaning Results

After cleaning the data, it's important to verify the results to ensure the accuracy and quality of the data. This can be done by:
- Running consistency checks
- Validating data against predefined rules or external sources
- Sampling data for manual inspection

---
# Course – 4: Process Data from Dirty to Clean

## Data Integrity

### 1. **Data Integrity**
Data integrity refers to the **accuracy**, **completeness**, **consistency**, and **trustworthiness** of data throughout its lifecycle. Maintaining data integrity is vital for ensuring that the data remains reliable for analysis and decision-making.

### 2. **Data Integrity Principles**
- **Validity**: Ensures that the data adheres to defined business rules or constraints.
- **Accuracy**: The degree of conformity of data to a standard or true value.
- **Completeness**: The extent to which all required data is known and accounted for.
- **Consistency**: Ensures that data values are equivalent across different systems.

---

## Data Cleaning

### 1. **Data Cleaning Steps**
Before cleaning the data, it’s important to:
- **Make a copy** of the data set to preserve the original data.
- **Remove duplicates** to eliminate redundancy.
- **Remove extra spaces & blanks** to standardize the data.
- **Fix spelling errors** and **inconsistent capitalization**.
- **Correct punctuation and typos**.
- **Remove unnecessary formatting**.

### 2. **Syntax in Data Cleaning**
- Syntax refers to a **predetermined structure** that dictates the required information and its correct placement.

---

## Spreadsheet Tools and Functions

### 1. **Spreadsheet Tools**
- **Conditional Formatting**: Changes how cells appear when certain conditions are met.
- **Text String**: A group of characters within a cell, often composed of letters.
- **Split**: Divides text according to a specified character, placing each fragment into a new cell.
- **Concatenate**: Joins multiple text strings into one single string.

### 2. **Common Functions**
- **COUNTIF**: Counts the number of cells that match a specified value.
  - Syntax: `=COUNTIF(range, "value")`
- **LEN**: Returns the length of a text string.
  - Syntax: `=LEN(range)`
- **LEFT**: Extracts a specified number of characters from the left side of a string.
  - Syntax: `=LEFT(range, number_of_characters)`
- **MID**: Extracts a segment from the middle of a text string.
  - Syntax: `=MID(range, start_position, number_of_characters)`
- **TRIM**: Removes leading, trailing, and repeated spaces from data.
  - Syntax: `=TRIM(range)`
- **CONCATENATE**: Combines multiple text strings into one.
  - Syntax: `=CONCATENATE(item1, item2)`

### 3. **Advanced Functions**
- **VLOOKUP**: Searches for a specific value in a column and returns a corresponding value from another column.
  - Syntax: `=VLOOKUP(value, range, column_number, FALSE)`
  - Use `FALSE` for an exact match.
- **SUBSTR()**: Extracts a substring from a specified position in a text string.
- **DISTINCT**: Removes duplicates in the result of a query.
- **CAST()**: Converts a value from one data type to another.
- **FLOAT**: Represents numbers that include decimals.
- **CONCAT()**: Adds text strings together to create a new string.
- **COALESCE()**: Returns the first non-null value from a list.

---

## Data Merging and Mapping

### 1. **Data Merging**
- **Data Merging**: The process of combining two or more datasets into a single dataset, ensuring they are compatible for further analysis.

### 2. **Compatibility**
- **Compatibility** refers to how well two or more datasets work together without conflict.

### 3. **Data Mapping**
- Data mapping involves matching fields from one data source to another. This helps ensure that data from various sources can be integrated and analyzed effectively.

---

## Reporting and Documentation

### 1. **Reporting**
- **Verification**: A process to confirm that data-cleaning efforts have been successful, and the resulting data is accurate and reliable.
- **Changelog**: A file that contains a chronologically ordered list of modifications made to a project.

### 2. **Documentation**
The process of tracking changes, additions, deletions, and errors involved in your data-cleaning efforts. It helps in:
- Recovering from data-cleaning errors.
- Informing others about changes.
- Determining the overall quality of the cleaned data.

---

## Schema and Data Structure

### 1. **Schema**
A **schema** is a way of describing how data is organized and structured. It provides a blueprint for how data is related and how different fields are used within a database or dataset.

---

## Miscellaneous Data Terms

### 1. **Merger**
- A merger is an agreement that unites two organizations into a single, new one.

### 2. **Field and Field Length**
- **Field**: A single piece of information from a row or column of a spreadsheet.
- **Field Length**: A tool for determining how many characters can be keyed into a field.

### 3. **Text String**
- A **text string** is a group of characters within a cell, most often composed of letters.

---



